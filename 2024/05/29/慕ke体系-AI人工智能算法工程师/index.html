

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/images/about/avatar-icon.jpeg">
  <link rel="icon" href="/images/about/avatar-icon.jpeg">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Tan ChuYang">
  <meta name="keywords" content="">
  
    <meta name="description" content="1. 深度卷积神经网络（Deep CNN）深度卷积神经网络通过增加更多的卷积层和池化层来捕捉更多的图像特征，从而提高图像分类的准确率。以下是一个使用VGG16模型的示例，该模型在ImageNet挑战中表现优异。 from tensorflow.keras.applications import VGG16 from tensorflow.keras.preprocessing.image impo">
<meta property="og:type" content="article">
<meta property="og:title" content="慕ke体系-AI人工智能算法工程师">
<meta property="og:url" content="http://example.com/2024/05/29/%E6%85%95ke%E4%BD%93%E7%B3%BB-AI%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AE%97%E6%B3%95%E5%B7%A5%E7%A8%8B%E5%B8%88/index.html">
<meta property="og:site_name" content="羊小羊的博客">
<meta property="og:description" content="1. 深度卷积神经网络（Deep CNN）深度卷积神经网络通过增加更多的卷积层和池化层来捕捉更多的图像特征，从而提高图像分类的准确率。以下是一个使用VGG16模型的示例，该模型在ImageNet挑战中表现优异。 from tensorflow.keras.applications import VGG16 from tensorflow.keras.preprocessing.image impo">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2024-05-28T23:53:26.000Z">
<meta property="article:modified_time" content="2024-06-06T10:20:11.608Z">
<meta property="article:author" content="Tan ChuYang">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>慕ke体系-AI人工智能算法工程师 - 羊小羊的博客</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.7","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":false,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"left","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":1},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 5.4.2"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 60vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>羊小羊的博客</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于羊小羊</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/images/background-images/orange.jpeg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.2)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="慕ke体系-AI人工智能算法工程师"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-05-29 07:53" pubdate>
          2024年5月29日 早上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          1.1k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          10 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="padding-left: 2rem; margin-right: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">慕ke体系-AI人工智能算法工程师</h1>
            
              <p id="updated-time" class="note note-info" style="">
                
                  
                    本文最后更新于 2024年6月6日 晚上
                  
                
              </p>
            
            
              <div class="markdown-body">
                
                <h2 id="1-深度卷积神经网络（Deep-CNN）"><a href="#1-深度卷积神经网络（Deep-CNN）" class="headerlink" title="1. 深度卷积神经网络（Deep CNN）"></a>1. 深度卷积神经网络（Deep CNN）</h2><p>深度卷积神经网络通过增加更多的卷积层和池化层来捕捉更多的图像特征，从而提高图像分类的准确率。以下是一个使用VGG16模型的示例，该模型在ImageNet挑战中表现优异。</p>
<div class="code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">from</span> tensorflow.keras.applications <span class="hljs-keyword">import</span> VGG16
<span class="hljs-keyword">from</span> tensorflow.keras.preprocessing.image <span class="hljs-keyword">import</span> ImageDataGenerator
<span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> layers, models

<span class="hljs-comment"># 加载预训练的VGG16模型</span>
vgg16_base = VGG16(weights=<span class="hljs-string">&#x27;imagenet&#x27;</span>, include_top=<span class="hljs-literal">False</span>, input_shape=(<span class="hljs-number">150</span>, <span class="hljs-number">150</span>, <span class="hljs-number">3</span>))

<span class="hljs-comment"># 冻结卷积基</span>
vgg16_base.trainable = <span class="hljs-literal">False</span>

<span class="hljs-comment"># 构建模型</span>
model = models.Sequential()
model.add(vgg16_base)
model.add(layers.Flatten())
model.add(layers.Dense(<span class="hljs-number">256</span>, activation=<span class="hljs-string">&#x27;relu&#x27;</span>))
model.add(layers.Dense(<span class="hljs-number">1</span>, activation=<span class="hljs-string">&#x27;sigmoid&#x27;</span>))

<span class="hljs-comment"># 编译模型</span>
model.<span class="hljs-built_in">compile</span>(optimizer=<span class="hljs-string">&#x27;adam&#x27;</span>,
              loss=<span class="hljs-string">&#x27;binary_crossentropy&#x27;</span>,
              metrics=[<span class="hljs-string">&#x27;accuracy&#x27;</span>])

<span class="hljs-comment"># 数据预处理</span>
train_datagen = ImageDataGenerator(rescale=<span class="hljs-number">1.</span>/<span class="hljs-number">255</span>)
validation_datagen = ImageDataGenerator(rescale=<span class="hljs-number">1.</span>/<span class="hljs-number">255</span>)

train_generator = train_datagen.flow_from_directory(
    <span class="hljs-string">&#x27;data/train&#x27;</span>,
    target_size=(<span class="hljs-number">150</span>, <span class="hljs-number">150</span>),
    batch_size=<span class="hljs-number">20</span>,
    class_mode=<span class="hljs-string">&#x27;binary&#x27;</span>)

validation_generator = validation_datagen.flow_from_directory(
    <span class="hljs-string">&#x27;data/validation&#x27;</span>,
    target_size=(<span class="hljs-number">150</span>, <span class="hljs-number">150</span>),
    batch_size=<span class="hljs-number">20</span>,
    class_mode=<span class="hljs-string">&#x27;binary&#x27;</span>)

<span class="hljs-comment"># 训练模型</span>
history = model.fit(
    train_generator,
    steps_per_epoch=<span class="hljs-number">100</span>,
    epochs=<span class="hljs-number">30</span>,
    validation_data=validation_generator,
    validation_steps=<span class="hljs-number">50</span>)</code></pre></div>

<h2 id="2-长短期记忆网络（LSTM）"><a href="#2-长短期记忆网络（LSTM）" class="headerlink" title="2. 长短期记忆网络（LSTM）"></a>2. 长短期记忆网络（LSTM）</h2><p>LSTM是RNN的一种变体，擅长处理长时间依赖问题。以下是一个改进版的LSTM实现，用于文本生成任务。</p>
<div class="code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">from</span> tensorflow.keras.layers <span class="hljs-keyword">import</span> Embedding, LSTM, Dense
<span class="hljs-keyword">from</span> tensorflow.keras.preprocessing.text <span class="hljs-keyword">import</span> Tokenizer
<span class="hljs-keyword">from</span> tensorflow.keras.preprocessing.sequence <span class="hljs-keyword">import</span> pad_sequences
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

<span class="hljs-comment"># 文本数据</span>
data = <span class="hljs-string">&quot;&quot;&quot;Your text data here&quot;&quot;&quot;</span>

<span class="hljs-comment"># 文本预处理</span>
tokenizer = Tokenizer()
tokenizer.fit_on_texts([data])
total_words = <span class="hljs-built_in">len</span>(tokenizer.word_index) + <span class="hljs-number">1</span>

input_sequences = []
<span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> data.split(<span class="hljs-string">&#x27;\n&#x27;</span>):
    token_list = tokenizer.texts_to_sequences([line])[<span class="hljs-number">0</span>]
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(token_list)):
        n_gram_sequence = token_list[:i+<span class="hljs-number">1</span>]
        input_sequences.append(n_gram_sequence)

<span class="hljs-comment"># 填充序列</span>
max_sequence_len = <span class="hljs-built_in">max</span>([<span class="hljs-built_in">len</span>(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> input_sequences])
input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding=<span class="hljs-string">&#x27;pre&#x27;</span>))

<span class="hljs-comment"># 创建预测变量</span>
xs, labels = input_sequences[:,:-<span class="hljs-number">1</span>],input_sequences[:,-<span class="hljs-number">1</span>]
ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)

<span class="hljs-comment"># 构建模型</span>
model = tf.keras.Sequential()
model.add(Embedding(total_words, <span class="hljs-number">100</span>, input_length=max_sequence_len-<span class="hljs-number">1</span>))
model.add(LSTM(<span class="hljs-number">150</span>))
model.add(Dense(total_words, activation=<span class="hljs-string">&#x27;softmax&#x27;</span>))

<span class="hljs-comment"># 编译模型</span>
model.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">&#x27;categorical_crossentropy&#x27;</span>, optimizer=<span class="hljs-string">&#x27;adam&#x27;</span>, metrics=[<span class="hljs-string">&#x27;accuracy&#x27;</span>])

<span class="hljs-comment"># 训练模型</span>
history = model.fit(xs, ys, epochs=<span class="hljs-number">100</span>, verbose=<span class="hljs-number">1</span>)

<span class="hljs-comment"># 文本生成</span>
seed_text = <span class="hljs-string">&quot;Your seed text&quot;</span>
next_words = <span class="hljs-number">50</span>

<span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(next_words):
    token_list = tokenizer.texts_to_sequences([seed_text])[<span class="hljs-number">0</span>]
    token_list = pad_sequences([token_list], maxlen=max_sequence_len-<span class="hljs-number">1</span>, padding=<span class="hljs-string">&#x27;pre&#x27;</span>)
    predicted = np.argmax(model.predict(token_list, verbose=<span class="hljs-number">0</span>), axis=-<span class="hljs-number">1</span>)
    output_word = <span class="hljs-string">&quot;&quot;</span>
    <span class="hljs-keyword">for</span> word, index <span class="hljs-keyword">in</span> tokenizer.word_index.items():
        <span class="hljs-keyword">if</span> index == predicted:
            output_word = word
            <span class="hljs-keyword">break</span>
    seed_text += <span class="hljs-string">&quot; &quot;</span> + output_word
<span class="hljs-built_in">print</span>(seed_text)</code></pre></div>

<h2 id="3-注意力机制和Transformer模型"><a href="#3-注意力机制和Transformer模型" class="headerlink" title="3. 注意力机制和Transformer模型"></a>3. 注意力机制和Transformer模型</h2><p>Transformer模型引入了注意力机制，在自然语言处理任务中表现出色。以下是一个简单的Transformer实现，用于机器翻译任务。</p>
<div class="code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">from</span> tensorflow.keras.layers <span class="hljs-keyword">import</span> Dense, LayerNormalization, Embedding, MultiHeadAttention, Dropout
<span class="hljs-keyword">from</span> tensorflow.keras.models <span class="hljs-keyword">import</span> Model
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

<span class="hljs-keyword">class</span> <span class="hljs-title class_">TransformerBlock</span>(tf.keras.layers.Layer):
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, embed_dim, num_heads, ff_dim, rate=<span class="hljs-number">0.1</span></span>):
        <span class="hljs-built_in">super</span>(TransformerBlock, self).__init__()
        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
        self.ffn = tf.keras.Sequential(
            [Dense(ff_dim, activation=<span class="hljs-string">&quot;relu&quot;</span>), Dense(embed_dim),]
        )
        self.layernorm1 = LayerNormalization(epsilon=<span class="hljs-number">1e-6</span>)
        self.layernorm2 = LayerNormalization(epsilon=<span class="hljs-number">1e-6</span>)
        self.dropout1 = Dropout(rate)
        self.dropout2 = Dropout(rate)

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">call</span>(<span class="hljs-params">self, inputs, training</span>):
        attn_output = self.att(inputs, inputs)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(inputs + attn_output)
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        <span class="hljs-keyword">return</span> self.layernorm2(out1 + ffn_output)

<span class="hljs-comment"># 创建Transformer模型</span>
<span class="hljs-keyword">class</span> <span class="hljs-title class_">TokenAndPositionEmbedding</span>(tf.keras.layers.Layer):
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, maxlen, vocab_size, embed_dim</span>):
        <span class="hljs-built_in">super</span>(TokenAndPositionEmbedding, self).__init__()
        self.token_emb = Embedding(input_dim=vocab_size, output_dim=embed_dim)
        self.pos_emb = Embedding(input_dim=maxlen, output_dim=embed_dim)

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">call</span>(<span class="hljs-params">self, x</span>):
        maxlen = tf.shape(x)[-<span class="hljs-number">1</span>]
        positions = tf.<span class="hljs-built_in">range</span>(start=<span class="hljs-number">0</span>, limit=maxlen, delta=<span class="hljs-number">1</span>)
        positions = self.pos_emb(positions)
        x = self.token_emb(x)
        <span class="hljs-keyword">return</span> x + positions

vocab_size = <span class="hljs-number">20000</span>  <span class="hljs-comment"># 词汇表大小</span>
maxlen = <span class="hljs-number">200</span>  <span class="hljs-comment"># 序列最大长度</span>
embed_dim = <span class="hljs-number">32</span>  <span class="hljs-comment"># 嵌入维度</span>
num_heads = <span class="hljs-number">2</span>  <span class="hljs-comment"># 注意力头数量</span>
ff_dim = <span class="hljs-number">32</span>  <span class="hljs-comment"># 前馈网络维度</span>

inputs = tf.keras.Input(shape=(maxlen,))
embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)
x = embedding_layer(inputs)
transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)
x = transformer_block(x)
x = tf.keras.layers.GlobalAveragePooling1D()(x)
x = tf.keras.layers.Dropout(<span class="hljs-number">0.1</span>)(x)
x = tf.keras.layers.Dense(<span class="hljs-number">20</span>, activation=<span class="hljs-string">&quot;relu&quot;</span>)(x)
x = tf.keras.layers.Dropout(<span class="hljs-number">0.1</span>)(x)
outputs = tf.keras.layers.Dense(<span class="hljs-number">2</span>, activation=<span class="hljs-string">&quot;softmax&quot;</span>)(x)

model = Model(inputs=inputs, outputs=outputs)

<span class="hljs-comment"># 编译和训练模型</span>
model.<span class="hljs-built_in">compile</span>(optimizer=<span class="hljs-string">&quot;adam&quot;</span>, loss=<span class="hljs-string">&quot;sparse_categorical_crossentropy&quot;</span>, metrics=[<span class="hljs-string">&quot;accuracy&quot;</span>])</code></pre></div>

<h2 id="4-自编码器（Autoencoder）"><a href="#4-自编码器（Autoencoder）" class="headerlink" title="4. 自编码器（Autoencoder）"></a>4. 自编码器（Autoencoder）</h2><p>自编码器用于无监督学习，尤其是在数据降维和特征提取方面。以下是一个简单的自编码器实现示例，用于图像去噪。</p>
<div class="code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> layers, models
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

<span class="hljs-comment"># 构建自编码器模型</span>
input_img = tf.keras.Input(shape=(<span class="hljs-number">28</span>, <span class="hljs-number">28</span>, <span class="hljs-number">1</span>))

<span class="hljs-comment"># 编码器</span>
x = layers.Conv2D(<span class="hljs-number">32</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">&#x27;relu&#x27;</span>, padding=<span class="hljs-string">&#x27;same&#x27;</span>)(input_img)
x = layers.MaxPooling2D((<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), padding=<span class="hljs-string">&#x27;same&#x27;</span>)(x)
x = layers.Conv2D(<span class="hljs-number">32</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">&#x27;relu&#x27;</span>, padding=<span class="hljs-string">&#x27;same&#x27;</span>)(x)
encoded = layers.MaxPooling2D((<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), padding=<span class="hljs-string">&#x27;same&#x27;</span>)(x)

<span class="hljs-comment"># 解码器</span>
x = layers.Conv2D(<span class="hljs-number">32</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">&#x27;relu&#x27;</span>, padding=<span class="hljs-string">&#x27;same&#x27;</span>)(encoded)
x = layers.UpSampling2D((<span class="hljs-number">2</span>, <span class="hljs-number">2</span>))(x)
x = layers.Conv2D(<span class="hljs-number">32</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">&#x27;relu&#x27;</span>, padding=<span class="hljs-string">&#x27;same&#x27;</span>)(x)
x = layers.UpSampling2D((<span class="hljs-number">2</span>, <span class="hljs-number">2</span>))(x)
decoded = layers.Conv2D(<span class="hljs-number">1</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">&#x27;sigmoid&#x27;</span>, padding=<span class="hljs-string">&#x27;same&#x27;</span>)(x)

autoencoder = models.Model(input_img, decoded)
autoencoder.<span class="hljs-built_in">compile</span>(optimizer=<span class="hljs-string">&#x27;adam&#x27;</span>, loss=<span class="hljs-string">&#x27;binary_crossentropy&#x27;</span>)

<span class="hljs-comment"># 加载数据并添加噪声</span>
(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()
x_train = x_train.astype(<span class="hljs-string">&#x27;float32&#x27;</span>) / <span class="hljs-number">255.</span>
x_test = x_test.astype(<span class="hljs-string">&#x27;float32&#x27;</span>) / <span class="hljs-number">255.</span>
x_train = np.reshape(x_train, (<span class="hljs-built_in">len</span>(x_train), <span class="hljs-number">28</span>, <span class="hljs-number">28</span>, <span class="hljs-number">1</span>))
x_test = np.reshape(x_test, (<span class="hljs-built_in">len</span>(x_test), <span class="hljs-number">28</span>, <span class="hljs-number">28</span>, <span class="hljs-number">1</span>))

noise_factor = <span class="hljs-number">0.5</span>
x_train_noisy = x_train + noise_factor * np.random.normal(loc=<span class="hljs-number">0.0</span>, scale=<span class="hljs-number">1.0</span>, size=x_train.shape)
x_test_noisy = x_test + noise_factor * np.random.normal(loc=<span class="hljs-number">0.0</span>, scale=<span class="hljs-number">1.0</span>, size=x_test.shape)
x_train_noisy = np.clip(x_train_noisy, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>)
x_test_noisy = np.clip(x_test_noisy, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>)

<span class="hljs-comment"># 训练自编码器</span>
autoencoder.fit(x_train_noisy, x_train,
                epochs=<span class="hljs-number">50</span>,
                batch_size=<span class="hljs-number">256</span>,
                shuffle=<span class="hljs-literal">True</span>,
                validation_data=(x_test_noisy, x_test))

<span class="hljs-comment"># 预测</span>
decoded_imgs = autoencoder.predict(x_test_noisy)</code></pre></div>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/AI/" class="print-no-link">#AI</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>慕ke体系-AI人工智能算法工程师</div>
      <div>http://example.com/2024/05/29/慕ke体系-AI人工智能算法工程师/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Tan ChuYang</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年5月29日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2024/05/31/%E7%BD%91%E6%98%93Three-js%E5%8F%AF%E8%A7%86%E5%8C%96%E4%BC%81%E4%B8%9A%E5%AE%9E%E6%88%98WEBGL%E8%AF%BE/" title="网易Three.js可视化企业实战WEBGL课2024">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">网易Three.js可视化企业实战WEBGL课2024</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/05/28/%E6%85%95ke%E6%85%95w-%E9%B8%BF%E8%92%99NEXT%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E5%B7%A5%E7%A8%8B%E5%B8%88/" title="慕ke慕w-鸿蒙NEXT应用开发工程师">
                        <span class="hidden-mobile">慕ke慕w-鸿蒙NEXT应用开发工程师</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      

    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>
  </div>
</div>





  



  




  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
